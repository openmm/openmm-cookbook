{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umbrella Sampling\n",
    " \n",
    " \n",
    "## Introduction\n",
    " \n",
    "Umbrella sampling is a technique used in molecular dynamics simulations to improve sampling in systems containing high barriers in the free energy landscape. With plain MD simulations the system can remain trapped in free energy minima whereas umbrella sampling adds extra biasing potentials to drive the system in the direction of a chosen collective variable (CV). This enables the calculation of free energy profiles much more efficiently than is possible with regular MD alone.\n",
    " \n",
    "## Theory\n",
    "This section explains more of the details behind umbrella sampling. Refer to [[1](#References), [2](#References)] for full information. The text in this section is from [[3](#References)].\n",
    " \n",
    "The free energy of a system in the canonical ensemble is\n",
    " \n",
    "$F=-k_B T \\text{log}(Z),$\n",
    " \n",
    "where $Z$ is the canonical partition function. For all but the smallest systems $Z$ is computationally intractable to calculate. However, often the most interesting information about a molecular system is given by the differences in the free energy across system states. A Collective Variable (CV; also called a reaction coordinate) can be defined which is a continuous variable that distinguishes different states. The simplest types of CVs are geometric distances (e.g. the distance between two molecules) but there are many other possibilities. The CV $x$ is a function of the atomic coordinates, $x(r)$, and multiple different realizations of $r$ can map to the same $x$. The probability distribution of the system can be written in terms of $x$:\n",
    " \n",
    "$p(x) \\propto \\int{ e^{-\\beta E(r)} \\delta (x-x(r))dr},$\n",
    " \n",
    "where we have integrated the Boltzmann distribution over all degrees of freedom for each value of $x$. The probability can be turned into a free energy:\n",
    " \n",
    "$F(x) = -k_B T \\text{log} (p(x)) + C,$\n",
    " \n",
    "where $C$ is a constant and unimportant as we are only interested in $∆F$. In theory, the free energy profile along $x$ could be computed by sampling the system in equilibrium and recording the probability histogram of the values of $x$ which occur. However, for any non-trivial potential energy surface it will take a very long time to achieve sufficient sampling to get an adequately converged histogram — the high energy states will not be sampled.\n",
    " \n",
    "To enhance the sampling umbrella sampling can be used. This adds additional biasing potentials $w(x)$ to the system to restrain it at certain values of $x$. The form of $w$ is usually a harmonic term:\n",
    " \n",
    "$w(x) = \\frac{1}{2} k (x-x_0)^2,$\n",
    " \n",
    "where $k$ is a constant with units of energy per units of $x$ squared. We then run multiple simulations, each restrained with a different $w$, and then combine them to generate a probability distribution that sufficiently samples the whole range of $x$. The process is illustrated in figure 1 and explained in more detail as follows.\n",
    "\n",
    "\n",
    "\n",
    "![umbrella_sampling](umbrella_sampling.svg)\n",
    "\n",
    "**Figure 1. Umbrella sampling method to compute a free energy profile.** (a) Multiple biasing potentials are placed across the collective variable $x$. The blue curve is the free energy of the system which we are trying to calculate. (b) Simulations are run for each window $w$. The resulting biased probability distributions $P'(x)$ are plotted. (c) The unbiased free energies $F_i$ from each window. They are each offset by a different $C_i$. (d) The Weighted Histogram Analysis Method (WHAM) is used to combine the windows and compute the free energy curve.\n",
    "\n",
    "\n",
    "\n",
    "With a biasing potential $w(x(r))$ the potential energy of the system becomes\n",
    " \n",
    "$E'(r) = E(r) + w((x(r)))$\n",
    " \n",
    "which leads to a probability distribution (in the canonical ensemble) of\n",
    " \n",
    "$p'(x) \\propto \\int e^{-\\beta (E + w)} \\delta (x - x(r)) dr \\propto p(x) e^{-\\beta w(x)},$\n",
    " \n",
    "and a free energy of\n",
    " \n",
    "$F'(x) = -k_B T \\text{log}(p(x)) + w(x) + C = F(x) + w(x) + C.$\n",
    " \n",
    "Thus, the unbiased free energy $F$ can be obtained by subtracting the biasing potential $w$ from the biased free energy $F'$. However, when more than one biasing window is used the value of $C$ cannot be neglected as it will be different for each window. For multiple biasing windows we have a set of unbiased (but offset by different $C_i$) free energies,\n",
    " \n",
    "$F_i(x) = -k_B T \\text{log}(p'_i) + w_i + C_i.$\n",
    " \n",
    "To compute $F$ over the full range of $x$ the different $F_i(x)$ need to be combined. This can be accomplished by the Weighted Histogram Analysis Method (WHAM) [[1](#References)]. The WHAM equations are shown in [appendix section 2](#WHAM-equations). The free energy profile is also called the Potential of Mean Force (PMF); in this example we will assume they are equivalent and use them interchangeably.\n",
    " \n",
    "## Umbrella sampling simulations\n",
    " \n",
    "Most umbrella sampling simulations have three main steps:\n",
    " \n",
    "1. Preparing the windows. This is usually done using Steered Molecular Dynamics (SMD; see [appendix section 1](#Steered-MD)). \n",
    "2. Running the windows. These can be computed in parallel to take advantage of compute resources.\n",
    "3. Analysing the results. Typically this involves computing a PMF with WHAM. \n",
    " \n",
    "Often you will find in step 3 that the simulations do not produce a nicely converged PMF. You will need to return to step 1 and change some settings. This trial and improvement feedback loop is a normal part of the process. For this tutorial we will use settings already known to work.\n",
    " \n",
    "## System\n",
    " \n",
    "This tutorial will use umbrella sampling to compute the free energy profile of the end-to-end distance ($r$) of deca-alanine in vacuum. Deca-alanine is commonly used as a toy system [[4](#References)]. Its equilibrium structure is a stable alpha-helix. Starting with the alpha-helix structure we will first perform a SMD simulation to pull it from a helix into a coil. Next, we will run 24 umbrella sampling windows in the range 1.3nm to 3.3nm. Finally, we will compute the PMF along $r$. Figure 2 shows the initial alpha-helix structure and the final extended coil structure.\n",
    "\n",
    "![deca-alanine](deca-alanine.png)\n",
    "\n",
    "**Figure 2** Structure of deca-alanine for end-to-end distance $r$=1.3 and $r$=3.3nm.\n",
    " \n",
    "## Step 1 - Setting up the windows with SMD\n",
    " \n",
    "The script below does the following steps:\n",
    "-   Loads in a PDB file.\n",
    "-   Defines a collective variable between the first and last alpha-carbon.\n",
    "-   Adds a harmonic restraint to the CV.\n",
    "-   Runs a simulation where the location of the harmonic restraint is moved with constant velocity from 1.3nm to 3.3nm (This is called constant velocity steered MD).\n",
    "-   Saves a configuration for each of the 24 equally spaced windows between 1.3nm and 3.3nm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmm as mm\n",
    "import openmm.app as app\n",
    "import openmm.unit as unit\n",
    "from sys import stdout\n",
    "import numpy as np\n",
    "\n",
    "pdb = app.PDBFile('deca-ala.pdb')\n",
    "\n",
    "forcefield = app.ForceField('amber14-all.xml')\n",
    "\n",
    "# We have a single molecule in vacuum so we use no cutoff.\n",
    "system = forcefield.createSystem(pdb.topology, nonbondedMethod=app.NoCutoff, constraints=app.HBonds, hydrogenMass=1.5*unit.amu)\n",
    "integrator = mm.LangevinMiddleIntegrator(300*unit.kelvin, 1/unit.picosecond, 0.004*unit.picoseconds)\n",
    "simulation = app.Simulation(pdb.topology, system, integrator)\n",
    "simulation.context.setPositions(pdb.positions)\n",
    "simulation.reporters.append(app.DCDReporter('smd_traj.dcd', 10000))\n",
    "simulation.reporters.append(app.StateDataReporter(stdout, 10000, step=True, time=True, potentialEnergy=True, temperature=True, speed=True))\n",
    "\n",
    "# equilibrate\n",
    "simulation.context.setVelocitiesToTemperature(300*unit.kelvin)\n",
    "simulation.step(1000)\n",
    "\n",
    "# define the CV as the distance between the CAs of the two end residues\n",
    "index1 = 8\n",
    "index2 = 98\n",
    "cv = mm.CustomBondForce('r')\n",
    "cv.addBond(index1, index2)\n",
    "\n",
    "# now setup SMD\n",
    "\n",
    "# starting value\n",
    "r0 = 1.3*unit.nanometers\n",
    "\n",
    "# force constant\n",
    "fc_pull = 1000.0*unit.kilojoules_per_mole/unit.nanometers**2 \n",
    "\n",
    "# pulling speed\n",
    "v_pulling = 0.02*unit.nanometers/unit.picosecond # nm/ps\n",
    "\n",
    "# simulation time step\n",
    "dt = simulation.integrator.getStepSize()\n",
    "\n",
    "# total number of steps\n",
    "total_steps = 30000 # 120ps\n",
    "\n",
    "# number of steps to run between incrementing r0 (1 makes the simulation slow)\n",
    "increment_steps = 10\n",
    "\n",
    "# define a harmonic restraint on the CV\n",
    "# the location of the restrain will be moved as we run the simulation\n",
    "# this is constant velocity steered MD\n",
    "pullingForce = mm.CustomCVForce('0.5 * fc_pull * (cv-r0)^2')\n",
    "pullingForce.addGlobalParameter('fc_pull', fc_pull)\n",
    "pullingForce.addGlobalParameter('r0', r0)\n",
    "pullingForce.addCollectiveVariable(\"cv\", cv)\n",
    "system.addForce(pullingForce)\n",
    "simulation.context.reinitialize(preserveState=True)\n",
    "\n",
    "# define the windows\n",
    "# during the pulling loop we will save specific configurations corresponding to the windows\n",
    "windows = np.linspace(1.3, 3.3, 24)\n",
    "window_coords = []\n",
    "window_index = 0\n",
    "\n",
    "# SMD pulling loop\n",
    "for i in range(total_steps//increment_steps):\n",
    "    simulation.step(increment_steps)\n",
    "    current_cv_value = pullingForce.getCollectiveVariableValues(simulation.context)\n",
    "    \n",
    "    if (i*increment_steps)%5000 == 0:\n",
    "        print(\"r0 = \", r0, \"r = \", current_cv_value)\n",
    "    \n",
    "    # increment the location of the CV based on the pulling velocity\n",
    "    r0 += v_pulling * dt * increment_steps\n",
    "    simulation.context.setParameter('r0',r0)\n",
    "\n",
    "    # check if we should save this config as a window starting structure\n",
    "    if (window_index < len(windows) and current_cv_value >= windows[window_index]):\n",
    "        window_coords.append(simulation.context.getState(getPositions=True, enforcePeriodicBox=False).getPositions())\n",
    "        window_index += 1\n",
    "\n",
    "# save the window structures\n",
    "for i, coords in enumerate(window_coords):\n",
    "    outfile = open(f'window_{i}.pdb', 'w')\n",
    "    app.PDBFile.writeFile(simulation.topology,coords, outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the script has completed running there will be 24 new pdb files called \"window_n.pdb\" where n is an integer from 0 to 23.\n",
    " \n",
    "We now have the initial configurations for the umbrella sampling windows.\n",
    " \n",
    "## Step 2 - Running the windows\n",
    " \n",
    "The script to run the windows is very similar to the script in step 1. The key differences are that we load in an initial structure that corresponds to each specific window and that the harmonic restraint on the CV does not move. The script below defines a function to run one window. It re-uses the `Simulation` we created in step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_window(window_index):\n",
    "\n",
    "    print('running window', window_index)\n",
    "    \n",
    "    # load in the starting configuration for this window\n",
    "    pdb = app.PDBFile(f'window_{window_index}.pdb')\n",
    "\n",
    "    # we can reuse the existing Simulation\n",
    "    simulation.context.setPositions(pdb.positions)\n",
    "\n",
    "    # set the fixed location of the harmonic restraint for this window\n",
    "    r0 = windows[window_index]\n",
    "    simulation.context.setParameter('r0', r0)\n",
    "\n",
    "    # run short equilibration with new positions and r0\n",
    "    simulation.context.setVelocitiesToTemperature(300*unit.kelvin)\n",
    "    simulation.step(1000)\n",
    "\n",
    "    # run the data collection\n",
    "\n",
    "    # total number of steps\n",
    "    total_steps = 100000 # 400 ps\n",
    "\n",
    "    # frequency to record the current CV value\n",
    "    record_steps = 1000\n",
    "\n",
    "    # run the simulation and record the value of the CV.\n",
    "    cv_values=[]\n",
    "    for i in range(total_steps//record_steps):\n",
    "        simulation.step(record_steps)\n",
    "\n",
    "        # get the current value of the cv\n",
    "        current_cv_value = pullingForce.getCollectiveVariableValues(simulation.context)\n",
    "        cv_values.append([i, current_cv_value[0]])\n",
    "\n",
    "    # save the CV timeseries to a file so we can postprocess \n",
    "    np.savetxt(f'cv_values_window_{window_index}.txt', np.array(cv_values))\n",
    "\n",
    "    print('Completed window', window_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run all 24 windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(24):\n",
    "    run_window(n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the window simulations have completed you will have the CV timeseries files: \"cv_values_window_n.txt\"\n",
    "\n",
    "## Step 3 - Analysis - compute the PMF\n",
    "\n",
    "The first thing to check is that the histograms of the CV timeseries have good overlap. Here is an example:\n",
    "![histogram](hist.png)\n",
    "\n",
    "\n",
    "You can plot yours with the script below\n",
    "(This script also produces the metadata file we will need for the next step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the histograms\n",
    "metafilelines = []\n",
    "for i in range(len(windows)):\n",
    "    data = np.loadtxt(f'cv_values_window_{i}.txt')\n",
    "    plt.hist(data[:,1])\n",
    "    metafileline = f'cv_values_window_{i}.txt {windows[i]} 1000\\n'\n",
    "    metafilelines.append(metafileline)\n",
    "\n",
    "plt.xlabel(\"r (nm)\")\n",
    "plt.ylabel(\"count\")\n",
    "\n",
    "with open(\"metafile.txt\", \"w\") as f:\n",
    "    f.writelines(metafilelines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the PMF we can use WHAM [[1](#References)]. An easy to use and widely compatible implementation is the WHAM program by Alan Grossfield which can be downloaded here: http://membrane.urmc.rochester.edu/?page_id=126. It is a C program so it will need to be compiled. The command below should work on Linux and Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://membrane.urmc.rochester.edu/sites/default/files/wham/wham-release-2.0.11.tgz\n",
    "!tar xf wham-release-2.0.11.tgz\n",
    "!cd wham/wham && make"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `wham` we need a metadata file that lists the names of each CV timeseries file, the location of the harmonic restraints, and the value of the spring constant. We created this in the histogram plotting script earlier.\n",
    " \n",
    "The `wham` program is run using command line arguments. Read the documentation to find out more: http://membrane.urmc.rochester.edu/sites/default/files/wham/doc.pdf\n",
    " \n",
    "The command below will compute the PMF from our data. The command line arguments correspond to a range of 1.3nm to 3.3nm, 50 histogram bins, a tolerance of 1e-6, and a temperature of 300K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./wham/wham/wham 1.3 3.3 50 1e-6 300 0 metafile.txt pmf.txt > wham_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the computed PMF. It should look something like this:\n",
    "![pmf.png](pmf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the PMF\n",
    "pmf = np.loadtxt(\"pmf.txt\")\n",
    "plt.plot(pmf[:,0], pmf[:,1])\n",
    "plt.xlabel(\"r (nm)\")\n",
    "plt.ylabel(\"PMF (kJ/mol)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "You should now perform error analysis to confirm the PMF you have calculated is an accurate representation of the system you are simulating. Here are a few suggestions:\n",
    "\n",
    "- Run some completely independent repeats and check the computed PMFs are the same.\n",
    "- Perform the initial steered MD loop at a slower speed. If this step is too fast your windows will have initial states that are far from equilibrium.\n",
    "- Run the windows for longer. If you have sampled enough then with longer runtime the calculated PMF should be the same. If the PMF is different it means your initial simulations were not long enough. Increase the runtime until the calculated PMFs are the same.\n",
    "- Similarly, using more windows you should get the same results.\n",
    "\n",
    "Other tips:\n",
    "\n",
    "- If the histograms have poor overlap you will need to use more windows and/or reduce the spring constant.\n",
    "- The windows do not need to be linearly spaced and they can have different spring constants.\n",
    " \n",
    "\n",
    "## References\n",
    "\n",
    "[1] Kumar, S., Rosenberg, J.M., Bouzida, D., Swendsen, R.H. and Kollman, P.A. (1992), *The weighted histogram analysis method for free-energy calculations on biomolecules. I. The method.* J. Comput. Chem., 13: 1011-1021. https://doi.org/10.1002/jcc.540130812  \n",
    "[2] Kästner, J. (2011), *Umbrella sampling.* WIREs Comput Mol Sci, 1: 932-942. https://doi.org/10.1002/wcms.66  \n",
    "[3] Farr, S. (2021), https://doi.org/10.17863/CAM.72078  \n",
    "[4] Park, S., Khalili-Araghi, F., Tajkhorshid, E., and Schulten, K. (2003), *Free energy calculation from steered molecular dynamics simulations using Jarzynski’s equality.* J. Chem. Phys., 119 (6): 3559–3566. https://doi.org/10.1063/1.1590311  \n",
    "\n",
    "## Appendix\n",
    " \n",
    "### Steered MD\n",
    " \n",
    "Steered MD is a non-equilibrium method which means great care must be taken to ensure the results you get are meaningful. In this tutorial steered MD is just used in the setup phase and we do not calculate any properties with it.\n",
    "In constant velocity steered MD the biasing potential has the form\n",
    " \n",
    "$w = \\frac{1}{2} k (x-x_0(t))^2,\n",
    "x_0(t) = x_0(0)+vt,$\n",
    " \n",
    "which is just a moving version of the umbrella window bias potential.\n",
    " \n",
    "### WHAM equations\n",
    "The WHAM equations [1] are:\n",
    " \n",
    "$P(x_j) = \\frac{\\sum^{N_w}_i h_i(x_j)}{\\sum^{N_w}_i n_i e^ {\\beta(C_i - w_i(x_j))} },$\n",
    " \n",
    "$C_i = -k_B T \\log\\left( \\sum_j P(x_j) e^{-\\beta w_i(x_j)} \\right).$\n",
    " \n",
    "Where they have been written in a fully discretized form. $P(x_j)$ is the resulting unbiased probability distribution where $j$ is the index for the discrete set of $x_j$ that $P$ is computed over. $N_w$ is the number of windows, $i$ is the index of each window, $n_i$ is the number of data points (realizations of $x$) in the $i$-th window trajectory, $h_i(x_j)$ is the number of points in histogram bin $j$ from trajectory $i$, and  $w_i$ are the biasing potentials. Both equations depend on each other so must be solved self-consistently. In practice this is solved iteratively: initial guesses of $C_i$ are chosen, $P$ is then calculated using the first equation, new values of $C_i$ are then calculated using the second equation, and the process is iterated until the differences between successive values are sufficiently small.\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cookbook3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "nbsphinx": {
   "execute": "never"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
